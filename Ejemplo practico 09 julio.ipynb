Ejemplo pr√°ctico durante la clase (9-jul-2024, 18:47)
Por: Andr√©s Felipe Escall√≥n Portilla

[ ]
# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Create a dataset
# Let¬¥s build the values lists
value_n_list = ['Andrew', 'Phillip', 'John']
print(value_n_list)

value_w_list = [50,         78,      91.5] # [kg]
value_h_list = [1.76,      1.87,     1.69] # [m]
# value_bmi_list will be calculated: bmi = w/(h^2)
#value_bmi_list = [25,25,25] # init values [kg/m2]

# Let¬¥s use a dictionary ({key:value})
# with the format {"str":list}
data_dict = {"name":value_n_list,
             "weight":value_w_list,
             "height":value_h_list} #,
              #"BMI":value_bmi_list}

print(data_dict)

# Turn a dictionary into a dataframe
df = pd.DataFrame(data_dict)

print(df)
# Call a variable
df

[ ]
df

[ ]
df

[ ]
df

[ ]
# prompt: Con DataFrame df: add another column

df['bmi'] = df['weight'] / (df['height'] ** 2)
df


[ ]
df.describe()

Making some transformations on the df
[ ]
# z = x / y*y
df["BMI"] =  df["weight"] / df["height"]**2
df

De acuerdo a los resultados puede conlcuir que:

-El valor max es: -

[ ]
df["BMI"].dtype
dtype('float64')
[ ]
# TO-DO: create another column with integers and turn it to float, such as:
df["BMI"] = df["BMI"].astype(float)
[ ]
df["BMI"].dtype
dtype('float64')
[ ]
df["name"].dtype
# Homework: how to verify that a column contains string
dtype('O')
[ ]
df

Init steps towards EDA (Exploratory Data Analisys):
Homework: perform a full EDA with your own invented dataset with at least 10 rows

[ ]
# Descriptive stats
df_stats = df.describe()
df_stats

TO-DO: please analyze the results (univariate: describe() / multivariate: correlation matrix)
[ ]
#df["health_condition"] = 'within the normal range' if 18.0<=df['BMI']<=25.0 else 'out of the normal range'
#df
Prompt used in chat GPT (by OpenAI) / Gemini (by Google) / Bing (Copilot by Microsoft) to solve the above error:
You are a python expert, please help with the error I will show later that is appearing when I run this code in Google collab: "df["health_condition"] = 'within the normal range' if 18.0<=df['BMI']<=25.0 else 'out of the normal range'".

The error is:

ValueError Traceback (most recent call last) in <cell line: 1>() ----> 1 df["health_condition"] = 'within the normal range' if 18.0<=df['BMI']<=25.0 else 'out of the normal range' 2 df

/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py in nonzero(self) 1525 @final 1526 def nonzero(self) -> NoReturn: -> 1527 raise ValueError( 1528 f"The truth value of a {type(self).name} is ambiguous. " 1529 "Use a.empty, a.bool(), a.item(), a.any() or a.all()."

ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().

[ ]
df

[ ]
print(df)
      name  weight  height        bmi        BMI
0   Andrew    50.0    1.76  16.141529  16.141529
1  Phillip    78.0    1.87  22.305471  22.305471
2     John    91.5    1.69  32.036693  32.036693
[ ]
df_stats

[ ]
print(df_stats)
          weight    height        bmi        BMI
count   3.000000  3.000000   3.000000   3.000000
mean   73.166667  1.773333  23.494564  23.494564
std    21.167979  0.090738   8.014020   8.014020
min    50.000000  1.690000  16.141529  16.141529
25%    64.000000  1.725000  19.223500  19.223500
50%    78.000000  1.760000  22.305471  22.305471
75%    84.750000  1.815000  27.171082  27.171082
max    91.500000  1.870000  32.036693  32.036693
[ ]
df["health_condition"] = np.where(  (df['BMI'] >= 18.0) & (df['BMI'] <= 25.0) , 'within the normal range', 'out of the normal range' )
df


[ ]
# Define a function to determine health condition
def determine_health_condition(bmi):
    if 18.0 <= bmi <= 25.0:
        return 'within the normal range'
    else:
        return 'out of the normal range'

# Apply the function to create the new column
df["health_condition4"] = df["BMI"].apply(determine_health_condition)

[ ]
print(df)
df

[ ]
# Define a function to determine health condition
def determine_health_condition7(bmi):
    """
    if 18.0 <= bmi <= 25.0:
        return 'within the normal range'
    else:
        return 'out of the normal range'
    """
    return 'within the normal range' if 18.0 <= bmi <= 25.0 else 'out of the normal range'

# Apply the function to create the new column
df["health_condition6"] = df["BMI"].apply(determine_health_condition7)
df

Please remove the unnecessary columns and search how to upload/download the df as .csv and .json and .xlsx
Correlation matrix (14-jun-2024)
ChatGPT prompt used:

"you¬¥re a python expert, please give code to get the correlation matrix of a dataframe with a simple example and calculus explanation"

[ ]
‚Ü≥ 1 celda oculta
A more complete example with synthetic data given by ChatGPT
[ ]
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Generate synthetic data
np.random.seed(42)  # for reproducibility

data = {
    'A': np.random.randn(100),
    'B': np.random.randn(100) * 2,
    'C': np.random.randn(100) + 1,
    'D': np.random.randn(100) - 1,
}

df = pd.DataFrame(data)

# Calculate the correlation matrix
correlation_matrix = df.corr()

# Print the correlation matrix
print("Correlation Matrix:")
print(correlation_matrix)

# Visualize the correlation matrix using a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()


[ ]
data
{'A': array([ 0.49671415, -0.1382643 ,  0.64768854,  1.52302986, -0.23415337,
        -0.23413696,  1.57921282,  0.76743473, -0.46947439,  0.54256004,
        -0.46341769, -0.46572975,  0.24196227, -1.91328024, -1.72491783,
        -0.56228753, -1.01283112,  0.31424733, -0.90802408, -1.4123037 ,
         1.46564877, -0.2257763 ,  0.0675282 , -1.42474819, -0.54438272,
         0.11092259, -1.15099358,  0.37569802, -0.60063869, -0.29169375,
        -0.60170661,  1.85227818, -0.01349722, -1.05771093,  0.82254491,
        -1.22084365,  0.2088636 , -1.95967012, -1.32818605,  0.19686124,
         0.73846658,  0.17136828, -0.11564828, -0.3011037 , -1.47852199,
        -0.71984421, -0.46063877,  1.05712223,  0.34361829, -1.76304016,
         0.32408397, -0.38508228, -0.676922  ,  0.61167629,  1.03099952,
         0.93128012, -0.83921752, -0.30921238,  0.33126343,  0.97554513,
        -0.47917424, -0.18565898, -1.10633497, -1.19620662,  0.81252582,
         1.35624003, -0.07201012,  1.0035329 ,  0.36163603, -0.64511975,
         0.36139561,  1.53803657, -0.03582604,  1.56464366, -2.6197451 ,
         0.8219025 ,  0.08704707, -0.29900735,  0.09176078, -1.98756891,
        -0.21967189,  0.35711257,  1.47789404, -0.51827022, -0.8084936 ,
        -0.50175704,  0.91540212,  0.32875111, -0.5297602 ,  0.51326743,
         0.09707755,  0.96864499, -0.70205309, -0.32766215, -0.39210815,
        -1.46351495,  0.29612028,  0.26105527,  0.00511346, -0.23458713]),
 'B': array([-2.83074148, -0.84129065, -0.68542903, -1.60455454, -0.32257142,
         0.80810171,  3.7723718 ,  0.34915563,  0.51510078, -0.14889183,
        -3.83754243, -0.05302775,  0.12046042,  4.92648422, -0.38472193,
         0.60309468, -0.06942354, -2.33735608,  2.28564563,  1.50386607,
         1.58206389, -1.81877491,  2.80558862, -2.80370213,  1.17371419,
         4.38091125, -1.98107265, -1.13259546,  0.19930273, -1.00695131,
        -3.10132686,  0.13712595, -2.12460743,  0.94718486, -1.83884847,
         3.09986881, -1.56650658, -0.64412303,  1.62703443, -2.46172863,
         0.45491987,  2.61428551, -3.21496647,  0.36926772,  0.51976559,
         1.56364574, -2.47390142, -2.64091323,  1.04388313,  0.59396935,
         0.5009857 ,  0.69289642, -1.36004944,  0.46450739,  0.58614495,
        -1.42870284,  3.73154902,  0.94766584, -2.38260699,  1.31310722,
        -1.94936334,  1.57416921,  2.31719116, -1.64136464,  1.92675226,
         0.82556185,  1.64412032,  3.79358597, -0.49077623, -1.50747233,
        -1.77902886, -1.63162057, -0.15420342,  0.68230395,  0.5533816 ,
         1.6543665 ,  0.02600378,  2.90706815, -0.52931367,  5.44033833,
         1.2513347 , -1.71431511, -2.141785  ,  0.96494483, -0.44692557,
         1.42800099,  0.94647525, -0.14565783, -1.69358744, -3.02969445,
        -0.8930299 ,  1.71279759,  0.42818749, -2.49147756,  0.34636185,
         0.77063476, -1.76771487,  0.30745021,  0.11641744, -2.2859406 ]),
 'C': array([ 1.35778736,  1.56078453,  2.08305124,  2.05380205, -0.37766937,
         0.06217496,  1.51503527,  1.51378595,  1.51504769,  4.85273149,
         1.57089051,  2.13556564,  1.95400176,  1.65139125,  0.68473076,
         1.75896922,  0.22717479,  0.76318139,  0.51463645,  1.08187414,
         3.31465857, -0.86726519,  1.68626019, -0.61271587,  0.52806813,
         2.0889506 ,  1.06428002, -0.07774478,  0.28469629,  1.67959775,
         0.26963337,  1.21645859,  1.04557184,  0.34839965,  3.14394409,
         1.63391902, -1.02514259,  1.18645431,  0.33821354,  1.85243333,
         0.20747926,  0.88526356,  1.50498728,  1.86575519, -0.20029641,
         0.66549876,  0.52505469,  0.34667077,  2.76545424,  1.40498171,
        -0.26088395,  1.91786195,  3.1221562 ,  2.03246526, -0.51936997,
         0.51576593,  2.26691115,  0.29233053,  1.44381943,  1.77463405,
         0.07306953,  0.94047464, -2.24126734, -0.02438764,  0.74743185,
        -0.24778318,  2.6324113 , -0.43014138,  0.55995551,  1.13074058,
         2.44127329, -0.43586215,  2.16316375,  1.01023306,  0.01849135,
         1.46210347,  1.1990597 ,  0.39978312,  1.06980208,  0.6146864 ,
         1.11351735,  1.66213067,  2.58601682, -0.2378155 ,  3.13303337,
        -0.9520878 ,  0.8482149 ,  1.58831721,  1.28099187,  0.37730048,
         0.79187775,  0.50699907,  0.41063524,  1.8496021 ,  1.35701549,
         0.3070904 ,  1.89959988,  1.30729952,  1.81286212,  1.62962884]),
 'D': array([-1.82899501, -1.56018104, -0.25270639, -0.38962973, -1.02090159,
        -0.88267262,  0.2776649 , -1.59157139, -0.45290262, -1.20219265,
        -1.2176812 ,  0.09877685, -0.17458365, -0.18649036,  0.30547881,
        -0.97899616, -0.31804703, -1.31026676, -0.67583365, -1.13014305,
        -0.90300404, -0.40484297, -1.81822068,  1.09238728, -2.00601738,
        -2.21418861,  0.15811087, -0.20833731, -0.37588018, -0.37165449,
        -1.01224677, -1.89725437, -0.92419544, -1.67716171, -0.02488027,
        -1.14705738, -1.8254972 , -1.32138584, -0.58706855, -1.56372455,
        -1.8222204 , -0.75631279, -0.75503343, -1.50694318, -1.47103831,
        -0.76795006, -2.44808434, -2.40746377, -1.71844422, -1.21344715,
        -0.68909243,  0.47535622, -0.14234038, -1.15993853, -1.01901621,
        -2.00252936, -1.01851314, -1.28865864, -0.67728144, -1.82723094,
        -0.48065349,  0.53273891, -1.10876015, -0.59828828, -0.30985601,
        -1.40122047, -0.77590752, -0.9874076 , -0.9023239 , -1.77300978,
        -0.97548983, -0.50200171,  0.45114361, -0.04072917,  1.15318246,
        -1.76734756, -0.12767936, -0.81665799,  1.18980293, -1.80829829,
        -1.83972184, -1.59939265, -3.12389572, -1.52575502, -1.75913266,
        -0.84960621, -0.65824402,  0.87617084, -0.04957616, -1.57690366,
        -1.89841467, -0.50808083, -2.32023321,  0.83145877,  0.17944012,
        -1.46917565, -2.71313453,  0.35387237, -1.11453985,  0.23781631])}
[ ]
df

Consultar c√≥mo es el c√°lculo de la matriz de correlaci√≥n (PEND):
Chat GPT Prompt: "Please, give me the explanation mathematically about the way the correlation matrix computation is performed"

Es una herramienta estad√≠stica que muestra las correlaciones entre todas las variables en un conjunto de datos. Se utiliza principalmente para entender c√≥mo las variables se relacionan entre s√≠ y para identificar patrones o dependencias lineales.

El c√°lculo de la matriz de correlaci√≥n implica los siguientes pasos b√°sicos:

1- Organizaci√≥n de datos: Tener un conjunto de datos donde se mide al menos dos variables para cada observaci√≥n. Por ejemplo, podr√≠amos tener variables como edad, ingreso, gasto mensual, etc., para cada individuo en un estudio.

2- C√°lculo de la correlaci√≥n: Para calcular la correlaci√≥n entre dos variables (digamos X e Y), se utiliza un coeficiente de correlaci√≥n. El coeficiente de correlaci√≥n m√°s com√∫nmente usado es el coeficiente de correlaci√≥n de Pearson, que mide la relaci√≥n lineal entre dos variables continuas. Se calcula de la siguiente manera:

Formula cal matriz correlacion2.PNG

donde:

Captura1.PNG

3- Construcci√≥n de la matriz: Una vez calculados todos los coeficientes de correlaci√≥n entre todas las variables del conjunto de datos, estos se organizan en una matriz cuadrada, donde las filas y columnas representan las variables. La diagonal principal de la matriz contiene siempre unos (correlaci√≥n de una variable consigo misma).

4- Interpretaci√≥n: La matriz de correlaci√≥n resultante permite interpretar la fuerza y la direcci√≥n de las relaciones entre las variables. Los valores del coeficiente de correlaci√≥n van de -1 a 1:

Cerca de 1 indica una correlaci√≥n positiva fuerte (las variables aumentan juntas).
Cerca de -1 indica una correlaci√≥n negativa fuerte (una variable aumenta mientras la otra disminuye).
Cerca de 0 indica una correlaci√≥n d√©bil o inexistente.
5- Visualizaci√≥n: A menudo, se visualiza la matriz de correlaci√≥n mediante un mapa de calor (heatmap), donde los valores m√°s altos de correlaci√≥n se muestran en tonos m√°s oscuros o m√°s intensos.

Es importante recordar que la correlaci√≥n no implica causalidad; es decir, solo porque dos variables est√©n correlacionadas, no significa necesariamente que una causa la otra. Sin embargo, la matriz de correlaci√≥n es una herramienta poderosa para explorar y comprender las relaciones dentro de un conjunto de datos.

Resultado:

Incluir formulas como si estuvieran escritas en un tablero

# E`sto tiene formato de c√≥digo`
Tarea: Consultar qu√© es y c√≥mo funciona la matriz de confusi√≥n (clasificaci√≥n)
La matriz de confusi√≥n es una herramienta fundamental en el campo del aprendizaje autom√°tico y la estad√≠stica, especialmente en problemas de clasificaci√≥n. Su funci√≥n principal es mostrar el desempe√±o de un modelo de clasificaci√≥n comparando las predicciones del modelo con los valores reales de los datos.

Estructura de la Matriz de Confusi√≥n

En una matriz de confusi√≥n t√≠pica, los elementos diagonales (de izquierda arriba a derecha abajo) representan las predicciones correctas, mientras que los elementos fuera de la diagonal indican errores de predicci√≥n. Aqu√≠ est√°n los componentes principales de la matriz:

Verdaderos positivos (TP): Estas son las instancias que el modelo predijo Elemento de lista correctamente como pertenecientes a la clase positiva.
Falsos positivos (FP): Estas son las instancias que el modelo predijo incorrectamente como pertenecientes a la clase positiva (cuando en realidad pertenecen a otra clase).
Verdaderos negativos (TN): Estas son las instancias que el modelo predijo correctamente como no pertenecientes a la clase positiva.
Falsos negativos (FN): Estas son las instancias que el modelo predijo incorrectamente como no pertenecientes a la clase positiva (cuando en realidad s√≠ pertenecen a la clase positiva).
Funcionamiento de la Matriz de Confusi√≥n

Generaci√≥n de predicciones: Primero, el modelo de clasificaci√≥n realiza predicciones sobre un conjunto de datos de prueba.

Comparaci√≥n con valores reales: Luego, las predicciones del modelo se comparan con los valores reales conocidos de las etiquetas de clase (ground truth).

Construcci√≥n de la matriz: Con base en estas comparaciones, se construye la matriz de confusi√≥n, donde se cuentan las instancias correctamente clasificadas y las incorrectamente clasificadas en cada clase.

Interpretaci√≥n:

Diagonal principal: Muestra el n√∫mero de predicciones correctas para cada clase.
Fuera de la diagonal principal: Muestra los errores cometidos por el modelo, donde cada celda (ùëñ,ùëó) representa cu√°ntas instancias de la clase ùëñ se predijeron como clase ùëó.
Importancia de la Matriz de Confusi√≥n

La matriz de confusi√≥n proporciona una visi√≥n detallada del rendimiento del modelo de clasificaci√≥n en t√©rminos de precisi√≥n, sensibilidad, especificidad y otros indicadores clave:

Exactitud (Accuracy): Proporci√≥n de predicciones correctas respecto al total de predicciones.
Precisi√≥n (Precision): Proporci√≥n de predicciones positivas correctas respecto al total de predicciones positivas hechas por el modelo.
Recuperaci√≥n o Sensibilidad (Recall o Sensitivity): Proporci√≥n de instancias positivas que fueron correctamente predichas por el modelo.
Especificidad (Specificity): Proporci√≥n de instancias negativas que fueron correctamente predichas por el modelo.
La matriz de confusi√≥n es fundamental para evaluar y comparar diferentes modelos de clasificaci√≥n y para ajustar los umbrales de decisi√≥n seg√∫n los requisitos espec√≠ficos del problema.

En resumen, la matriz de confusi√≥n proporciona una representaci√≥n visual y cuantitativa del rendimiento del modelo de clasificaci√≥n, ayudando a entender d√≥nde y c√≥mo el modelo est√° cometiendo errores en sus predicciones.

[ ]
# TO-DO
Las metricas...

Consultar las m√©tricas de desempe√±o para regresi√≥n y clasificaci√≥n
Las m√©tricas de desempe√±o son herramientas fundamentales para evaluar cuantitativamente el rendimiento de modelos en problemas de regresi√≥n y clasificaci√≥n. A continuaci√≥n, te proporciono un resumen de las principales m√©tricas utilizadas en cada tipo de problema:

M√©tricas de Desempe√±o para Regresi√≥n En problemas de regresi√≥n, el objetivo es predecir valores num√©ricos continuos. Aqu√≠ est√°n algunas de las m√©tricas comunes utilizadas para evaluar modelos de regresi√≥n:

Eror Absoluto Medio (Mean Absolute Error, MAE):
Captura1.PNG

Error Cuadr√°tico Medio (Mean Squared Error, MSE): Captura1.PNG
Ra√≠z del Error Cuadr√°tico Medio (Root Mean Squared Error, RMSE): oeficiente de Determinaci√≥n (R-cuadrado o R2): Captura1.PNG
image.png

M√©tricas de Desempe√±o para Clasificaci√≥n

En problemas de clasificaci√≥n, el objetivo es predecir la clase (etiqueta) a la que pertenece una muestra. Aqu√≠ est√°n algunas de las m√©tricas comunes utilizadas para evaluar modelos de clasificaci√≥n:

Exactitud (Accuracy):

                 N√∫mero de predicciones correcta
 Accuracy = ______________________________________
                 N√∫mero total de predicciones
Precisi√≥n y Recall (Sensibilidad): 2.1 Presici√≥n (Presicion):

                    TP
   Precisi√≥n = ____________
                 TP + FP
2.2 Recall o Sensibilidad (Recall o Sensitivity):

               TP
   Recall = ____________
               TP + FN

 Donde FN es el n√∫mero de falsos negativos. Recall mide la proporci√≥n de instancias positivas que fueron correctamente predichas por el modelo.              
Estas dos m√©tricas son complementarias y se utilizan para evaluar el rendimiento del modelo, especialmente en problemas donde una clase puede ser m√°s relevante que otra (por ejemplo, en diagn√≥sticos m√©dicos).

F1 - Score:

             Presicion * Recall
F1 = 2 * ___

             Presicion + Recall
El F1-score es la media arm√≥nica de precision y recall, proporcionando una m√©trica √∫nica que equilibra ambas medidas. Es √∫til cuando hay un desequilibrio entre las clases en el conjunto de datos.

Matriz de Confusi√≥n:

Aunque no es una m√©trica en s√≠ misma, la matriz de confusi√≥n es una herramienta esencial para visualizar y entender el rendimiento del modelo de clasificaci√≥n, como se explic√≥ anteriormente.

Selecci√≥n de M√©tricas

La elecci√≥n de las m√©tricas adecuadas depende del tipo de problema que est√©s abordando y de los objetivos espec√≠ficos de tu modelo. Es importante considerar las caracter√≠sticas del conjunto de datos, como el desbalance de clases en problemas de clasificaci√≥n, y seleccionar m√©tricas que proporcionen informaci√≥n relevante sobre el rendimiento del modelo en el contexto del problema particular que est√°s tratando de resolver.

Las metricas...

[ ]
# TO-DO
Las metricas...

[ ]
Fuentes de consulta:

https://chatgpt.com/

https://eragroup.eu/ejemplos-del-coeficiente-de-correlacion-de-pearson/

https://www.youtube.com/watch?v=r5WIImKV1XA&ab_channel=AprendeIAconLigdiGonzalez
